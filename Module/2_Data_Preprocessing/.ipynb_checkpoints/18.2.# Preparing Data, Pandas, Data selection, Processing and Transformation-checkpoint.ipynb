{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6642e4",
   "metadata": {},
   "source": [
    "## 18.2.1\n",
    "### Steps for Preparing Data\n",
    "After digging into unsupervised learning a bit, you realize that your first step in convincing *Accountability Accountants* to invest in cryptocurrency is to preprocess the data.\n",
    "\n",
    "You and Martha open up the dataset to get started preprocessing it. Together, you will want to manage unnecessary columns, rows with null values, and mixed data types before turning your algorithm loose.\n",
    "Data Selection\n",
    "\n",
    "Before moving data to our unsupervised algorithms, complete the following steps for preparing data:\n",
    "\n",
    "   - Data selection\n",
    "   - Data processing\n",
    "   - Data transformation\n",
    "\n",
    "Data selection entails making good choices about which data will be used. Consider what data is available, what data is missing, and what data can be removed. For example, say we have a dataset on city weather that consists of temperature, population, latitude and longitude, date, snowfall, and income. After looking through the columns, we can readily see that population and income data don't affect weather. We might also notice some rows are missing temperature data. In the data selection process, we would remove the population and income columns as well as any rows that don't record temperatures.\n",
    "\n",
    "#### Data Processing\n",
    "\n",
    "Data processing involves organizing the data by formatting, cleaning, and sampling it. In our dataset on city weather, if the date column has two different formats—mm-dd-yyyy (e.g., 01-23-1980) and month-data-year (e.g., jan-23-1980)—we would convert all dates to the same format.\n",
    "\n",
    "#### Data Transformation\n",
    "\n",
    "Data transformation entails transforming our data into a simpler format for storage and future use, such as a CSV, spreadsheet, or database file. Once our weather data is cleaned and processed, we would export the final version of the data as a CSV file for future analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f150f",
   "metadata": {},
   "source": [
    "## 18.2.2\n",
    "### Pandas Refresher\n",
    "When it comes to preprocessing data, you have good news for Martha. The Pandas Python library is really good at this! When Martha asks for a quick refresher on how to use Pandas for data munging, you know just the dataset to use—the iris dataset from the University of California, Irvine (UCI) Machine Learning Repository.\n",
    "\n",
    "Pandas is a Python library that is excellent for data munging. We'll be using the iris dataset from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/iris), a common dataset used throughout machine learning:\n",
    "\n",
    "   1. Store the raw iris.csv (https://archive.ics.uci.edu/ml/datasets/iris)\n",
    "\n",
    "   2. Open a new Jupyter Notebook.\n",
    "\n",
    "   3. Import your libraries:\n",
    "\n",
    "        import pandas as pd\n",
    "\n",
    "   4. To load the dataset in a Pandas DataFrame, enter the code below. Be sure to use the path to the stored CSV file (stored in an easy-to-access location):\n",
    "\n",
    "        - file_path = \"<folder path to stored data sets>/iris.csv\"\n",
    "        - iris_df = pd.read_csv(file_path)\n",
    "        - iris_df.head()\n",
    "\n",
    "   5. Select the fields of data you want:\n",
    "\n",
    "         - The CSV is read into a DataFrame. The resulting DataFrame displays the columns sepal_length_sepal_width, petl_length, petal_width, and class.\n",
    "\n",
    "    **note:**\n",
    "    Unsupervised learning will be used to determine the class of the iris plants later on in the module.\n",
    "\n",
    "   6. Drop the class field using the code below:\n",
    "         - new_iris_df = iris_df.drop([\"class\"], axis=1)\n",
    "        - new_iris_df.head()\n",
    "\n",
    "    Drop the class column from the DataFrame and display resulting DataFrame.\n",
    "\n",
    "**skill drill**\n",
    "\n",
    "Try reordering the columns so the sepal and petal lengths are the first two columns and the widths are the last two columns.\n",
    "End of text box.\n",
    "\n",
    "Cleaning this dataset appears complete with all the data in numerical form and the same type, so no data processing is needed. However, you'll encounter data transformations on datasets that contain categorical data or non-numeric features (e.g., transforming male and female categorical values to 0 and 1, respectively).\n",
    "\n",
    "Finally, the preprocessed DataFrame is saved on a new CSV file for future use. This is done by storing the file path in a variable, then using the Pandas to_csv() method to export the DataFrame to a CSV by supplying the file path and file name as arguments, as shown below:\n",
    "\n",
    "- output_file_path = \"<path to folder>/new_iris_data.csv\"\n",
    "- new_iris_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083df858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing 18.2.2\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../Datasets/iris.csv\"\n",
    "iris_df = pd.read_csv(file_path)\n",
    "iris_df.head()\n",
    "\n",
    "new_iris_df = iris_df.drop(['class'], axis = 1)\n",
    "new_iris_df.head()\n",
    "\n",
    "output_file_path = \"../Exported_Data/new_iris_data.csv\"\n",
    "new_iris_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10d1e0",
   "metadata": {},
   "source": [
    "## 18.2.3\n",
    "### Preprocessing Data With Pandas\n",
    "Martha is super grateful for the Pandas refresher—it's always fun to work with such a classic dataset! Now that you are both on the same page, you start to think critically about your cryptocurrency dataset.\n",
    "\n",
    "As mentioned, we don't know the output of the data, but that doesn't mean we shouldn't think about our data or that we should carelessly plug it into a model.\n",
    "\n",
    "Let's take a look at how we should start our data processing by loading in the shopping_data.csv (Links to an external site.)\n",
    "\n",
    "Read in shopping data and display the DataFrame.\n",
    "\n",
    "#### Questions for Data Preparation\n",
    "\n",
    "Unsupervised learning doesn't have a clear outcome or target variable like supervised learning, but it is used to find patterns. By properly preparing the data, we can select features that help us find patterns or groups.\n",
    "\n",
    "Before we begin, consider these questions:\n",
    "\n",
    "    What knowledge do we hope to glean from running an unsupervised learning model on this dataset?\n",
    "    What data is available? What type? What is missing? What can be removed?\n",
    "    Is the data in a format that can be passed into an unsupervised learning model?\n",
    "    Can I quickly hand off this data for others to use?\n",
    "\n",
    "Let's address the first question on our list:\n",
    "\n",
    "What knowledge do we hope to glean from running an unsupervised learning model on this dataset?\n",
    "\n",
    "It's a shopping dataset, so we can group together shoppers based on spending habits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cd6e483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Card Member</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID Card Member   Age  Annual Income  Spending Score (1-100)\n",
       "0           1         Yes  19.0          15000                    39.0\n",
       "1           2         Yes  21.0          15000                    81.0\n",
       "2           3          No  20.0          16000                     6.0\n",
       "3           4          No  23.0          16000                    77.0\n",
       "4           5          No  31.0          17000                    40.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing 18.2.3\n",
    "file_path = \"../Datasets/shopping_data.csv\"\n",
    "df_shopping = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
    "df_shopping.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45853bab",
   "metadata": {},
   "source": [
    "## 18.2.4\n",
    "### Data Selection\n",
    "It's not every day that you and Martha have a chance to convince an accounting firm to invest in cryptocurrency! So, you want to make sure you know how to select the data that will best help the model determine patterns or grouping.\n",
    "\n",
    "To help us select the data, let's return to some of the questions on our list.\n",
    "\n",
    "#### What data is available?\n",
    "\n",
    "First, account for the data you have. After all, you can't extract knowledge without data. We can use the columns method and output the columns, as shown below:\n",
    "\n",
    "    '# Columns\n",
    "    df_shopping.columns\n",
    "\n",
    "Looking at the columns, we see there is data for CustomerID, Age, Annual Income, and Spending Score:\n",
    "\n",
    "Displays a list that contains the columns CustomerID, Card Member, Age, Annual Income, and Spending Score (1-100)\n",
    "\n",
    "Now that we know what data we have, we can start thinking about possible analysis. For example, data points for features like Age and Annual Income might appear in our end result as groupings or clusters. However, there are no data points for items purchased, so our algorithms cannot discover related patterns.\n",
    "\n",
    "#### What type of data is available?\n",
    "\n",
    "Using the dtypes method, confirm the data type, which also will alert us if anything should be changed in the next step (e.g., converting text to numerical data). All the columns we plan to use in our model must contain a numerical data type:\n",
    "\n",
    "Use the dtypes method to display the data types of the shopping DataFrame.\n",
    "\n",
    "#### What data is missing?\n",
    "\n",
    "Next, let's see if any data is missing. Unsupervised learning models can't handle missing data. If you try to run a model on a dataset with missing data, you'll get an error such as the one below:\n",
    "\n",
    "     ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
    "\n",
    "If you initially had hoped to produce an outcome using a type of data, but it turned out more than 80% of those rows are empty, then the results won't be very accurate!\n",
    "\n",
    "For example, return to our Age and Income groups: If it turns out there are 1,200 rows without any Age data points, then we clearly can't use that column in our model. There is no set cutoff for missing data—that decision is left up to you, the analyst, and must be made based on your understanding of the business needs.\n",
    "\n",
    "**note:**\n",
    "Handling missing data is a complex topic that is out of scope for this unit. However, if you're interested, read this article (https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4) on the possible approaches to handling missing data.\n",
    "\n",
    "Pandas has the isnull() method to check for missing values. We'll loop through each column, check if there are null values, sum them up, and print out a readable total:\n",
    "\n",
    "Loop through the columns in the shopping DataFrame, check for null values, and print totals for each column.\n",
    "\n",
    "There will be a few rows with missing values that we'll need to handle. The judgement call will be to either remove these rows or decide that the dataset is not suitable for our model. In this case, we'll proceed with handling these values because they are a small percentage of the overall data.\n",
    "\n",
    "**important:**\n",
    "When deciding to proceed, the percentage of data missing isn't always the only determining factor. See the Note callout above for a resource on handling missing data.\n",
    "\n",
    "#### What data can be removed?\n",
    "\n",
    "You have begun to explore the data and have taken a look at null values. Next, determine if the data can be removed. Consider: Are there string columns that we can't use? Are there columns with excessive null data points? Was our decision to handle missing values to just remove them?\n",
    "\n",
    "In our example, there are no string type columns, and we made the decision that only a few rows have null data points, but not enough to remove a whole column's worth.\n",
    "\n",
    "Rows of data with null values can be removed with the dropna() method, as shown below:\n",
    "\n",
    "    '# Drop null rows\n",
    "    df_shopping = df_shopping.dropna()\n",
    "\n",
    "Duplicates can also be removed.\n",
    "\n",
    "Use the duplicated().sum() method to check for duplicates, as shown below:\n",
    "\n",
    "Use the duplicated().sum() method to determine how many duplicates are in the DataFrame. The result prints out zero duplicate entries.\n",
    "\n",
    "Looks good with no duplicates!\n",
    "\n",
    "To remove the column, just enter the code below:\n",
    "\n",
    "Drop the CustomerID column and display the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb345f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column CustomerID has 0 null values\n",
      "Column Card Member has 2 null values\n",
      "Column Age has 2 null values\n",
      "Column Annual Income has 0 null values\n",
      "Column Spending Score (1-100) has 1 null values\n",
      "Duplicate entries: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Card Member</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15000</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16000</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Card Member   Age  Annual Income  Spending Score (1-100)\n",
       "0         Yes  19.0          15000                    39.0\n",
       "1         Yes  21.0          15000                    81.0\n",
       "2          No  20.0          16000                     6.0\n",
       "3          No  23.0          16000                    77.0\n",
       "4          No  31.0          17000                    40.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing 18.2.4\n",
    "\n",
    "# Columns\n",
    "df_shopping.columns\n",
    "\n",
    "# List dataframe data types \n",
    "df_shopping.dtypes\n",
    "\n",
    "# Find null values \n",
    "for column in df_shopping.columns: \n",
    "    print(f\"Column {column} has {df_shopping[column].isnull().sum()} null values\")\n",
    "    \n",
    "# Drop null rows\n",
    "df_shopping = df_shopping.dropna()\n",
    "\n",
    "# Find suplicate entries \n",
    "print(f\"Duplicate entries: {df_shopping.duplicated().sum()}\")\n",
    "\n",
    "# Remove the CustomerID Column \n",
    "df_shopping.drop(columns=[\"CustomerID\"], inplace=True)\n",
    "df_shopping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ff4352",
   "metadata": {},
   "source": [
    "## 18.2.5\n",
    "### Data Processing\n",
    "Now that you know what kind of data you want to work, it's time to meet the needs for your unsupervised model.\n",
    "\n",
    "The next step is to move on from what you (the user) want to get out of your data and on to what the unsupervised model needs out of the data.\n",
    "\n",
    "Recall that in the data selection step, you, as the user, are exploring the data to see what kind of insights and analysis you might glean. You reviewed the columns available and the data types stored, and determined if there were missing values.\n",
    "\n",
    "For data processing, the focus is on making sure the data is set up for the unsupervised learning model, which requires the following:\n",
    "\n",
    "   - Null values are handled.\n",
    "   - Only numerical data is used.\n",
    "   - Values are scaled. In other words, data has been manipulated to ensure that the variance between the numbers won't skew results.\n",
    "\n",
    "**rewind\n",
    "\n",
    "Recall that when features have different scales, they can have a disproportionate impact on the model. The unscaled value could lead to messy graphs. Therefore, it is important to understand when to scale and normalize data. For example, if four columns of data are single digits, and the fifth column is in the millions, we would need to scale the fifth column to align the other four.**\n",
    "\n",
    "Let's return again to our list of questions.\n",
    "\n",
    "#### Is the data in a format that can be passed into an unsupervised learning model?\n",
    "\n",
    "We saw before that all our data had the correct type for each column; however, we know that our model can't have strings passed into it.\n",
    "\n",
    "To make sure we can use our string data, we'll transform our strings of Yes and No from the Card Member column to 1 and 0, respectively, by creating a function that will convert Yes to a 1 and anything else to 0.\n",
    "\n",
    "The function will then be run on the whole column with the .apply method, as shown below:\n",
    "\n",
    "Create a function to change the Yes from the Card Member column to a 1 and anything else to a 0. Then apply the function on the Card Member column of the shopping DataFrame.\n",
    "\n",
    "Also, there is one more thing you may notice about the data. The scale for Annual Income is much larger than all the other values in the dataset. We can adjust this format by dividing by 1,000 to rescale those data points, as shown below:\n",
    "\n",
    "Scale the Annual Income column down by dividing by 1,000. Then display the resulting DataFrame.\n",
    "\n",
    "**skill drill**\n",
    "\n",
    "Reformat the names of the columns so they contain no spaces or numbers.\n",
    "End of text box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2808114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Card Member</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Card Member   Age  Annual Income  Spending Score (1-100)\n",
       "0            0  19.0           15.0                    39.0\n",
       "1            0  21.0           15.0                    81.0\n",
       "2            0  20.0           16.0                     6.0\n",
       "3            0  23.0           16.0                    77.0\n",
       "4            0  31.0           17.0                    40.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing 18.2.5\n",
    "#Transform String column \n",
    "def change_string(member):\n",
    "    if member == \"Yes\":\n",
    "        return 1\n",
    "    else: \n",
    "        return 0 \n",
    "\n",
    "df_shopping[\"Card Member\"] = df_shopping[\"Card Member\"].apply(change_string)\n",
    "df_shopping.head()\n",
    "\n",
    "# Transform annual income \n",
    "df_shopping[\"Annual Income\"] = df_shopping[\"Annual Income\"]/1000\n",
    "df_shopping.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d39c9",
   "metadata": {},
   "source": [
    "## 18.2.6\n",
    "### Data Transformation\n",
    "You have done all this work to get your data ready to be passed into an unsupervised learning model, but what about when other teams need to use this data? The next step is transforming your data into a convenient way for others to use in the future.\n",
    "\n",
    "Data transformation involves thinking about the future. More times than not, there will be new data coming into your data storage (a place where raw data is stored before being touched), with many people working on different types of data analysis. We want to make sure that whoever wants to use the data in the future can do so.\n",
    "\n",
    "Let's return once more to our list of questions.\n",
    "\n",
    "#### Can I quickly hand off this data for others to use?\n",
    "\n",
    "The data now needs to be transformed back into a more user-friendly format. It would be nice if everyone was as great with DataFrames as you two; unfortunately, that is not the case. You'll want to convert the final product into a common data type like CSV or Excel files.\n",
    "\n",
    "Now that our data has been cleaned and processed, it is ready to be converted to a readable format for future use:\n",
    "\n",
    "    '# Saving cleaned data\n",
    "    file_path = \"<path to your folder>/shopping_data_cleaned.csv\"\n",
    "    df_shopping.to_csv(file_path, index=False)\n",
    "\n",
    "**skill drill**\n",
    "\n",
    "Try to export the data to a different format.\n",
    "End of text box.\n",
    "\n",
    "Now you know the questions to ask about your data and understand the Pandas processes used to help answer those questions. Different datasets have different issues. With practice, you'll get better at identifying these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378431be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing 18.2.6\n",
    "# Saving cleaned data\n",
    "file_path = \"../Exported_Data/shopping_data_cleaned.csv\"\n",
    "df_shopping.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1cbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlev",
   "language": "python",
   "name": "mlev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
